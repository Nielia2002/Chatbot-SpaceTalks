{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load your CSV dataset\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Astronauts.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Handle missing values\n",
        "df['mission_title'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Drop unnecessary 'id' column if present (duplicates 'number')\n",
        "if 'id' in df.columns:\n",
        "    df.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Function to clean text fields\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
        "\n",
        "# Generate structured text chunks and store in a new column\n",
        "def generate_text_chunk(row):\n",
        "    chunk = (\n",
        "        f\"Astronaut ID: {row['number']}. \"\n",
        "        f\"Name: {row['name']}. \"\n",
        "        f\"Nationality: {row['nationality']}. \"\n",
        "        f\"Mission Title: {row['mission_title']}. \"\n",
        "        f\"Mission Duration: {row['hours_mission']} hours. \"\n",
        "        f\"EVA Duration: {row['eva_hrs_mission']} hours. \"\n",
        "        f\"Total EVA Hours: {row['total_eva_hrs']} hours. \"\n",
        "        f\"Total Mission Hours: {row['total_hrs_sum']} hours.\"\n",
        "    )\n",
        "    return clean_text(chunk)\n",
        "\n",
        "# Apply chunk generation to each row\n",
        "df['text_chunk'] = df.apply(generate_text_chunk, axis=1)\n",
        "\n",
        "# Save cleaned data to new CSV file on Google Drive\n",
        "output_csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Astronauts_Cleaned.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Verify by displaying first few chunks\n",
        "print(df[['number', 'text_chunk']].head(3))\n",
        "\n",
        "print(f\"\\nCleaned data saved successfully at:\\n{output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEzaY8XMJghG",
        "outputId": "631bf68e-3c03-4771-9c93-5de32517de35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   number                                         text_chunk\n",
            "0       1  Astronaut ID: 1. Name: Gagarin, Yuri. National...\n",
            "1       2  Astronaut ID: 2. Name: Titov, Gherman. Nationa...\n",
            "2       3  Astronaut ID: 3. Name: Glenn, John H., Jr.. Na...\n",
            "\n",
            "Cleaned data saved successfully at:\n",
            "/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Astronauts_Cleaned.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9f8c2d96d235>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['mission_title'].fillna('Unknown', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load dataset from Google Drive\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Exoplanets.csv'\n",
        "df_exo = pd.read_csv(csv_path)\n",
        "\n",
        "# Inspect for missing values\n",
        "print(df_exo.isnull().sum())\n",
        "\n",
        "# Handle missing values (filling with placeholders or dropping)\n",
        "df_exo.fillna('Unknown', inplace=True)\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
        "\n",
        "# Create structured text chunks\n",
        "text_chunks_exo = []\n",
        "for idx, row in df_exo.iterrows():\n",
        "    chunk = f\"\"\"\n",
        "    Exoplanet Name: {row['name']}.\n",
        "    Distance from Earth: {row['distance']} light years.\n",
        "    Stellar System: {row.get('stellar_system', 'Unknown')}.\n",
        "    Discovery Method: {row.get('detection', 'Unknown')}.\n",
        "    Year of Discovery: {row['discovery_year']}.\n",
        "    Orbital Period: {row.get('orbital_period', 'Unknown')} days.\n",
        "    Planet Mass: {row.get('mass', 'Unknown')} Jupiter masses.\n",
        "    Planet Radius: {row.get('radius', 'Unknown')}.\n",
        "    \"\"\"\n",
        "    df_exo.at[idx, 'text_chunk'] = ' '.join(str(chunk).split())\n",
        "\n",
        "# Save cleaned data as CSV\n",
        "output_csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Exoplanets_Cleaned.csv'\n",
        "df_exo.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Verify chunks\n",
        "print(df_exo[['name', 'text_chunk']].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jndCNdqLodv",
        "outputId": "85c68b45-e5e3-45cb-dee2-003b9285b80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name                   0\n",
            "distance              17\n",
            "stellar_magnitude    161\n",
            "planet_type            0\n",
            "discovery_year         0\n",
            "mass_multiplier       23\n",
            "mass_wrt              23\n",
            "radius_multiplier     17\n",
            "radius_wrt            17\n",
            "orbital_radius       289\n",
            "orbital_period         0\n",
            "eccentricity           0\n",
            "detection_method       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d7136517282f>:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_exo.fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   name                                         text_chunk\n",
            "0  11 Comae Berenices b  Exoplanet Name: 11 Comae Berenices b. Distance...\n",
            "1    11 Ursae Minoris b  Exoplanet Name: 11 Ursae Minoris b. Distance f...\n",
            "2       14 Andromedae b  Exoplanet Name: 14 Andromedae b. Distance from...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load Planets.csv dataset from Google Drive\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/planets.csv'\n",
        "df_planets = pd.read_csv(csv_path)\n",
        "\n",
        "# Inspect missing values briefly\n",
        "print(df_planets.isnull().sum())\n",
        "\n",
        "# Fill missing values with placeholders ('Unknown')\n",
        "df_planets.fillna('Unknown', inplace=True)\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
        "\n",
        "# Generate meaningful text chunks\n",
        "for idx, row in df_planets.iterrows():\n",
        "    chunk = f\"\"\"\n",
        "    Host Name: {row['pl_hostname']}.\n",
        "    Planet Letter: {row['pl_letter']}.\n",
        "    Discovery Method: {row['pl_discmethod']}.\n",
        "    Number of Planets in System: {row['pl_pnum']}.\n",
        "    Orbital Period: {row['pl_orbper']} days.\n",
        "    Orbital Semi-major Axis: {row['pl_orbsmax']} AU.\n",
        "    Orbital Eccentricity: {row['pl_orbeccen']}.\n",
        "    Orbital Inclination: {row['pl_orbincl']} degrees.\n",
        "    Planet Mass: {row['pl_bmassj']} Jupiter masses.\n",
        "    Planet Radius: {row['pl_radj']} Jupiter radii.\n",
        "    Stellar Distance: {row['st_dist']} parsecs.\n",
        "    Stellar Magnitude: {row['st_optmag']}.\n",
        "    Stellar Temperature: {row['st_teff']} K.\n",
        "    Stellar Mass: {row['st_mass']} Solar masses.\n",
        "    Stellar Radius: {row['st_rad']} Solar radii.\n",
        "    \"\"\"\n",
        "    df_planets.at[idx, 'text_chunk'] = clean_text(chunk)\n",
        "\n",
        "# Save cleaned dataset as CSV\n",
        "output_csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/Planets_Cleaned.csv'\n",
        "df_planets.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Display first few chunks for verification\n",
        "print(df_planets[['pl_hostname', 'text_chunk']].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2D0W22eMzXL",
        "outputId": "c86b2b73-aa21-46d8-ebd6-c953abdf6511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rowid              0\n",
            "pl_hostname        0\n",
            "pl_letter          0\n",
            "pl_discmethod      0\n",
            "pl_pnum            0\n",
            "                ... \n",
            "st_raderr1       417\n",
            "st_raderr2       494\n",
            "st_radlim        358\n",
            "st_radblend      187\n",
            "rowupdate          0\n",
            "Length: 67, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-28bc6be0a323>:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_planets.fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  pl_hostname                                         text_chunk\n",
            "0      11 Com  Host Name: 11 Com. Planet Letter: b. Discovery...\n",
            "1      11 UMi  Host Name: 11 UMi. Planet Letter: b. Discovery...\n",
            "2      14 And  Host Name: 14 And. Planet Letter: b. Discovery...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load SpaceXMission.csv from Google Drive\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/SpaceXMission.csv'\n",
        "df_spacex = pd.read_csv(csv_path)\n",
        "\n",
        "# Quickly inspect missing values\n",
        "print(df_spacex.isnull().sum())\n",
        "\n",
        "# Fill missing values with placeholders ('Unknown')\n",
        "df_spacex.fillna('Unknown', inplace=True)\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
        "\n",
        "# Generate structured text chunks for each SpaceX mission\n",
        "for idx, row in df_spacex.iterrows():\n",
        "    chunk = f\"\"\"\n",
        "    Flight Number: {row['Flight Number']}.\n",
        "    Launch Date: {row['Launch Date']} at {row['Launch Time']}.\n",
        "    Launch Site: {row['Launch Site']}.\n",
        "    Vehicle Type: {row['Vehicle Type']}.\n",
        "    Payload Name: {row['Payload Name']} ({row['Payload Type']}), weighing {row['Payload Mass (kg)']} kg.\n",
        "    Orbit: {row['Payload Orbit']}.\n",
        "    Customer: {row['Customer Name']} ({row['Customer Type']}, {row['Customer Country']}).\n",
        "    Mission Outcome: {row['Mission Outcome']}.\n",
        "    Failure Reason: {row['Failure Reason']}.\n",
        "    Landing Type: {row['Landing Type']}, Landing Outcome: {row['Landing Outcome']}.\n",
        "    \"\"\"\n",
        "    df_spacex.at[idx, 'text_chunk'] = clean_text(chunk)\n",
        "\n",
        "# Save cleaned dataset as CSV\n",
        "output_csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/SpaceXMission_Cleaned.csv'\n",
        "df_spacex.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Verify by showing the first few text chunks\n",
        "print(df_spacex[['Flight Number', 'text_chunk']].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49FJUNlvOalN",
        "outputId": "327c2f84-8b6a-4f51-cb68-f42c7debaf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flight Number         0\n",
            "Launch Date           0\n",
            "Launch Time           0\n",
            "Launch Site           0\n",
            "Vehicle Type          0\n",
            "Payload Name          0\n",
            "Payload Type          3\n",
            "Payload Mass (kg)     8\n",
            "Payload Orbit         5\n",
            "Customer Name         2\n",
            "Customer Type         2\n",
            "Customer Country      2\n",
            "Mission Outcome       0\n",
            "Failure Reason       33\n",
            "Landing Type         20\n",
            "Landing Outcome      20\n",
            "dtype: int64\n",
            "  Flight Number                                         text_chunk\n",
            "0          F1-1  Flight Number: F1-1. Launch Date: 24 March 200...\n",
            "1          F1-2  Flight Number: F1-2. Launch Date: 21 March 200...\n",
            "2          F1-3  Flight Number: F1-3. Launch Date: 3 August 200...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1cd685cd642b>:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df_spacex.fillna('Unknown', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/NasaMarsRover/details.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to safely parse string dictionaries into Python dictionaries\n",
        "def parse_dict(s):\n",
        "    try:\n",
        "        return ast.literal_eval(s)\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "# Apply parsing\n",
        "df['camera'] = df['camera'].apply(parse_dict)\n",
        "df['rover'] = df['rover'].apply(parse_dict)\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
        "\n",
        "# Generate structured text chunks\n",
        "def create_text_chunk(row):\n",
        "    camera = row['camera']\n",
        "    rover = row['rover']\n",
        "    chunk = f\"\"\"\n",
        "    Image ID: {row['id']}.\n",
        "    Martian Sol (Day): {row['sol']}.\n",
        "    Earth Date: {row['earth_date']}.\n",
        "    Camera: {camera.get('full_name', 'Unknown')} (Camera ID: {camera.get('id', 'Unknown')}).\n",
        "    Rover: {rover.get('name', 'Unknown')}, Status: {rover.get('status', 'Unknown')}.\n",
        "    Rover Landing Date: {rover.get('landing_date', 'Unknown')}.\n",
        "    Rover Launch Date: {rover.get('launch_date', 'Unknown')}.\n",
        "    Total Photos Taken by Rover: {rover.get('total_photos', 'Unknown')}.\n",
        "    \"\"\"\n",
        "    return clean_text(chunk)\n",
        "\n",
        "# Apply to DataFrame\n",
        "df['text_chunk'] = df.apply(create_text_chunk, axis=1)\n",
        "\n",
        "# Save cleaned CSV\n",
        "output_csv_path = '/content/drive/MyDrive/Colab Notebooks/RAG-Chatbot/MarsRover_Cleaned.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Verify first few chunks\n",
        "print(df[['id', 'text_chunk']].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNbHpKcMP8Ui",
        "outputId": "1c3c0202-502d-4a58-f028-51aa9c0dc24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id                                         text_chunk\n",
            "0  102693  Image ID: 102693. Martian Sol (Day): 1000. Ear...\n",
            "1  102694  Image ID: 102694. Martian Sol (Day): 1000. Ear...\n",
            "2  102850  Image ID: 102850. Martian Sol (Day): 1000. Ear...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers pandas\n"
      ],
      "metadata": {
        "id": "3WUBUmwdRDce",
        "outputId": "d8e119a0-a264-491a-d212-4db662141ff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.7/664.8 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}